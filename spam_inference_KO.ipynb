{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tilon/Desktop/Tilon/myvenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/tilon/Desktop/Tilon/myvenv/lib/python3.13/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/KcBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/tilon/Desktop/Tilon/myvenv/lib/python3.13/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "\n",
      "ğŸ“¨ \"ì˜¤ëŠ˜ ì˜¤í›„ 2ì‹œì— íšŒì˜ê°€ ìˆìŠµë‹ˆë‹¤.\"\n",
      "âœ ì˜ˆì¸¡: HAM (ì‹ ë¢°ë„: 0.999)\n",
      "\n",
      "ğŸ“¨ \"ë¬´ë£Œì¿ í°! ì§€ê¸ˆ í´ë¦­í•˜ê³  ë°›ì•„ê°€ì„¸ìš”!\"\n",
      "âœ ì˜ˆì¸¡: SPAM (ì‹ ë¢°ë„: 0.9987)\n",
      "\n",
      "ğŸ“¨ \"ì‚¬ë‚´ ë³µì§€ ë³€ê²½ì‚¬í•­ì„ ê³µìœ ë“œë¦½ë‹ˆë‹¤.\"\n",
      "âœ ì˜ˆì¸¡: HAM (ì‹ ë¢°ë„: 0.9991)\n",
      "\n",
      "ğŸ“¨ \"365ì¼ ë‹¤ì´ì–´íŠ¸ ë¹„ë²•, ë‹¨ 3ì¼ë§Œ ê³µê°œ!\"\n",
      "âœ ì˜ˆì¸¡: SPAM (ì‹ ë¢°ë„: 0.9983)\n",
      "\n",
      "ğŸ“¨ \"ì´ë²¤íŠ¸ì— ë‹¹ì²¨ë˜ì…¨ìŠµë‹ˆë‹¤! ê²½í’ˆì„ ìˆ˜ë ¹í•˜ì„¸ìš”.\"\n",
      "âœ ì˜ˆì¸¡: SPAM (ì‹ ë¢°ë„: 0.9976)\n",
      "\n",
      "ğŸ“¨ \"í”„ë¡œì íŠ¸ ìë£Œë¥¼ íšŒëŒí•©ë‹ˆë‹¤.\"\n",
      "âœ ì˜ˆì¸¡: HAM (ì‹ ë¢°ë„: 0.9986)\n"
     ]
    }
   ],
   "source": [
    "# âœ… 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# âœ… 2. ëª¨ë¸ ê²½ë¡œ ì„¤ì •\n",
    "model_path = \"./KO_results\"  # í•™ìŠµ ê²°ê³¼ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬\n",
    "\n",
    "# âœ… 3. config.jsonì´ ì—†ì„ ê²½ìš° ëŒ€ë¹„ â€“ ì›ë³¸ ëª¨ë¸ì—ì„œ ë³µì‚¬\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(\"mps\")\n",
    "except OSError:\n",
    "    print(\"config.jsonì´ ì—†ì–´ ì›ë³¸ ëª¨ë¸ì—ì„œ ë³µì‚¬í•©ë‹ˆë‹¤.\")\n",
    "    from transformers import AutoConfig\n",
    "    config = AutoConfig.from_pretrained(\"beomi/KcBERT-base\", num_labels=2)\n",
    "    config.save_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config).to(\"mps\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# âœ… 4. í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[\\\\n\\\\r]\", \" \", text)\n",
    "    text = re.sub(r\"\\\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "# âœ… 5. ì¶”ë¡  í•¨ìˆ˜\n",
    "def predict_spam(text_list):\n",
    "    results = []\n",
    "    for text in text_list:\n",
    "        cleaned = clean_text(text)\n",
    "        inputs = tokenizer(\n",
    "            cleaned,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256\n",
    "        ).to(\"mps\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            prediction = torch.argmax(logits, dim=1).item()\n",
    "            label = \"SPAM\" if prediction == 1 else \"HAM\"\n",
    "            confidence = torch.softmax(logits, dim=1)[0][prediction].item()\n",
    "\n",
    "        results.append((text, label, round(confidence, 4)))\n",
    "    return results\n",
    "\n",
    "# âœ… 6. í…ŒìŠ¤íŠ¸ ë¬¸ì¥\n",
    "samples = [\n",
    "    # ğŸ“§ ì¼ë°˜ ì—…ë¬´ìš©\n",
    "    \"ê¸ˆì£¼ íšŒì˜ë¡ì„ ì²¨ë¶€ë“œë¦½ë‹ˆë‹¤. í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\",\n",
    "    \"ìƒˆ í”„ë¡œì íŠ¸ ì¼ì •ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë‹¤ìŒì£¼ íœ´ê°€ ì¼ì • ê³µìœ ë“œë¦½ë‹ˆë‹¤.\",\n",
    "    \"íšŒì˜ì‹¤ ì˜ˆì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ì¬ë¬´íŒ€ì— ì¸ë³´ì´ìŠ¤ë¥¼ ì „ì†¡í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì—…ë¬´ ë³´ê³ ì„œë¥¼ ë‚´ì¼ê¹Œì§€ ì œì¶œí•´ì£¼ì„¸ìš”.\",\n",
    "\n",
    "    # ğŸ’° ê´‘ê³ /ìŠ¤íŒ¸\n",
    "    \"ì§€ê¸ˆ ê°€ì…í•˜ë©´ 100% ë‹¹ì²¨ì˜ ê¸°íšŒ!\",\n",
    "    \"ë‹¨ 3ì¼ë§Œ! ë¬´ë£Œë¡œ ì²´í—˜í•˜ì„¸ìš”!\",\n",
    "    \"ìµœì‹  ìŠ¤ë§ˆíŠ¸í°, ê³µì§œë¡œ ë“œë¦½ë‹ˆë‹¤!\",\n",
    "    \"ë¬´ë£Œ í¬ì¸íŠ¸ ì ë¦½! ì˜¤ëŠ˜ ì•ˆ ë°›ìœ¼ë©´ ì†í•´!\",\n",
    "    \"ì‹ ê·œ íšŒì› í•œì •, ìŠ¤íƒ€ë²…ìŠ¤ ê¸°í”„í‹°ì½˜ ì¦ì •!\",\n",
    "    \"ì§‘ì—ì„œë„ í•˜ë£¨ 30ë¶„ìœ¼ë¡œ 500ë§Œì› ìˆ˜ìµ!\",\n",
    "    \"ì´ ë§í¬ë¥¼ í´ë¦­í•˜ê³  ë¹„ë°€ ì¿ í°ì„ ë°›ìœ¼ì„¸ìš”!\",\n",
    "    \"ë¯¸ì²­êµ¬ ë³´í—˜ê¸ˆ í™•ì¸í•´ë³´ì…¨ë‚˜ìš”?\",\n",
    "    \"ì†Œì§€í•˜ê³  ê³„ì‹  ì¹´ë“œê°€ ë‹¹ì²¨ë˜ì—ˆìŠµë‹ˆë‹¤!\",\n",
    "    \"ì´ ë©”ì¼ì„ 10ëª…ì—ê²Œ ë³´ë‚´ë©´ ì„ ë¬¼ì´ ë„ì°©í•©ë‹ˆë‹¤!\",\n",
    "\n",
    "    # ğŸ›’ ì‡¼í•‘/ì´ë²¤íŠ¸\n",
    "    \"11ë²ˆê°€ íƒ€ì„ë”œ, ì§€ê¸ˆ ì‹œì‘í•©ë‹ˆë‹¤!\",\n",
    "    \"ì¹´ì¹´ì˜¤ì‡¼í•‘ 3,000ì› ì¿ í°ì´ ë„ì°©í–ˆì–´ìš”.\",\n",
    "    \"ì˜¤ëŠ˜ì€ ì¥ë°”êµ¬ë‹ˆ ì¿ í°ì´ ìë™ ì ìš©ë©ë‹ˆë‹¤.\",\n",
    "    \"ê³ ê°ë‹˜ì„ ìœ„í•œ ë§ì¶¤ ìƒí’ˆì„ ì¤€ë¹„í–ˆì–´ìš”.\",\n",
    "    \"ì´ë²ˆ ì£¼ ì£¼ë§íŠ¹ê°€! ìµœëŒ€ 70% í• ì¸!\",\n",
    "\n",
    "    # ğŸ” ë³´ì•ˆ/í”¼ì‹± ì˜ì‹¬\n",
    "    \"ê·€í•˜ì˜ ê³„ì •ì—ì„œ ë¡œê·¸ì¸ ì‹œë„ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ë³´ì•ˆ ê°•í™”ë¥¼ ìœ„í•´ ë¹„ë°€ë²ˆí˜¸ë¥¼ ë³€ê²½í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì‹ ì› í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ì—¬ê¸°ë¥¼ í´ë¦­í•˜ì„¸ìš”.\",\n",
    "    \"ì´ì²´ ì˜¤ë¥˜ ë°œìƒ. ê³„ì¢Œ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
    "\n",
    "    # ğŸ’¬ ì¼ìƒ ë©”ì‹œì§€\n",
    "    \"ì ì‹¬ ë­ ë¨¹ì„ë˜?\",\n",
    "    \"ì˜¤ëŠ˜ ë‚ ì”¨ ë„ˆë¬´ ì¢‹ë‹¤!\",\n",
    "    \"ì£¼ë§ì— ì˜í™” ë³´ëŸ¬ ê°ˆë˜?\",\n",
    "    \"ì§‘ ì•ì— ë„ì°©í–ˆì–´~\",\n",
    "    \"ë‹¤ìŒ ì£¼ ìƒì¼ íŒŒí‹° ê¸°ëŒ€ë¼!\"\n",
    "]\n",
    "\n",
    "\n",
    "# âœ… 7. ê²°ê³¼ ì¶œë ¥\n",
    "results = predict_spam(samples)\n",
    "for text, label, conf in results:\n",
    "    print(f\"\\nğŸ“¨ \\\"{text}\\\"\\nâœ ì˜ˆì¸¡: {label} (ì‹ ë¢°ë„: {conf})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
